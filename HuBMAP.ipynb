{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuBMAP.ipynb",
      "provenance": [],
      "mount_file_id": "1AeQIzzQO-yl_-XRmr3fv0rKRxtkRLGQX",
      "authorship_tag": "ABX9TyPv774TqCXd/UHilvneQhEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankguo77/ML/blob/master/HuBMAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPrxNuE6cvvz"
      },
      "source": [
        "!pip install fastai -U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXWPBFsDdRJu"
      },
      "source": [
        "import fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7YOsLsAJdNOG",
        "outputId": "605a3665-6060-4a8b-b8ef-de733db7cfb6"
      },
      "source": [
        "fastai.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UgcZJKed15s",
        "outputId": "93f52917-393d-4286-df5e-9d34ac44a833"
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: zh-CN,zh;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-data-sets/979056/1662190/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201230%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201230T114554Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=4cf6863f6c624e463c1f2f63065842168abc72a07df969cd41496a08adb0553b88ca9b5cdc419e483460d9fda9ed28dcbc4e93a27c143b9efd30dfbcb1d1326cc827a683332309dde90b762e623559db3f2f0743c39b5166c0d785e35af3721abcaf762b9253b38870e020cf0902d1f0323fb0068d2d0d2cb4bc862282c06851f8c401c9e6ab9c19c0fb4583402fe0d42565c59540a3c565cd1d6406587074f9deed0ea1af760a6a4b86f91560e5be2536cfc21e74ba5cfc38839034dc559819dc32f8273e260e183854f2b4ea81e7da58ec675500b7014799a921d40cdb53ca6e6799fb548313695e5eac527c7f863eccb39111e97162409960c6bf9e2c751b\" -c -O 'archive.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-30 13:01:15--  https://storage.googleapis.com/kaggle-data-sets/979056/1662190/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201230%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201230T114554Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=4cf6863f6c624e463c1f2f63065842168abc72a07df969cd41496a08adb0553b88ca9b5cdc419e483460d9fda9ed28dcbc4e93a27c143b9efd30dfbcb1d1326cc827a683332309dde90b762e623559db3f2f0743c39b5166c0d785e35af3721abcaf762b9253b38870e020cf0902d1f0323fb0068d2d0d2cb4bc862282c06851f8c401c9e6ab9c19c0fb4583402fe0d42565c59540a3c565cd1d6406587074f9deed0ea1af760a6a4b86f91560e5be2536cfc21e74ba5cfc38839034dc559819dc32f8273e260e183854f2b4ea81e7da58ec675500b7014799a921d40cdb53ca6e6799fb548313695e5eac527c7f863eccb39111e97162409960c6bf9e2c751b\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.2.112, 172.217.164.144, 142.250.73.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.2.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 504951390 (482M) [application/zip]\n",
            "Saving to: ‘archive.zip’\n",
            "\n",
            "archive.zip         100%[===================>] 481.56M   196MB/s    in 2.5s    \n",
            "\n",
            "2020-12-30 13:01:18 (196 MB/s) - ‘archive.zip’ saved [504951390/504951390]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Til8qznrhr0y",
        "outputId": "abe5d57a-d9c0-47ec-94ab-635e7544bb02"
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: zh-CN,zh;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/22990/1698033/compressed/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1609588871&Signature=REiPH%2BHlj2kVSHTAAA%2FtISFz70SfzlrRG4ulNieOBaa8VGt5JYBccBqS9OdioD3ESk5%2FcJLLdl0v6wllQaU6zNNVmRm%2Bj4DDwoHtsTC4uUMNyYRGN3a8nigERUDPwX4J40DYnD4GqZLbRfnOFkSXPn9SdTxrWnirWlbtr0CzkUyUy%2F%2F%2Fl%2Fx86d9n%2B1o90AdcbXvSrijehZzDU53gvnoBmsr0hjLVGzxeZVYffxPj8Ws%2B4eydXJWt97ITM3caDbg057vEKMej4CqCx6%2BkXHsNrcWimSpe79XvQTLfZIEiDA8NlzyoTGfJH45ZoerOJ5h7hYEBQCTqtB2LVGOnif5CkA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip\" -c -O 'train.csv.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-30 13:01:20--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/22990/1698033/compressed/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1609588871&Signature=REiPH%2BHlj2kVSHTAAA%2FtISFz70SfzlrRG4ulNieOBaa8VGt5JYBccBqS9OdioD3ESk5%2FcJLLdl0v6wllQaU6zNNVmRm%2Bj4DDwoHtsTC4uUMNyYRGN3a8nigERUDPwX4J40DYnD4GqZLbRfnOFkSXPn9SdTxrWnirWlbtr0CzkUyUy%2F%2F%2Fl%2Fx86d9n%2B1o90AdcbXvSrijehZzDU53gvnoBmsr0hjLVGzxeZVYffxPj8Ws%2B4eydXJWt97ITM3caDbg057vEKMej4CqCx6%2BkXHsNrcWimSpe79XvQTLfZIEiDA8NlzyoTGfJH45ZoerOJ5h7hYEBQCTqtB2LVGOnif5CkA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.2.112, 172.217.164.144, 142.250.73.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.2.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2940565 (2.8M) [application/zip]\n",
            "Saving to: ‘train.csv.zip’\n",
            "\n",
            "\rtrain.csv.zip         0%[                    ]       0  --.-KB/s               \rtrain.csv.zip       100%[===================>]   2.80M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-12-30 13:01:20 (179 MB/s) - ‘train.csv.zip’ saved [2940565/2940565]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nqftCuKeGNT"
      },
      "source": [
        "from zipfile import ZipFile\r\n",
        "#zfs = ['train.parquet.zip','test.parquet.zip']\r\n",
        "zfs = ['archive.zip','train.csv.zip']\r\n",
        "\r\n",
        "for zf in zfs:\r\n",
        "  with ZipFile(zf, 'r') as z:\r\n",
        "    z.extractall(\".//data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg7zrOqyeQ3y"
      },
      "source": [
        "# zfs = ['train.csv.zip']\r\n",
        "\r\n",
        "# for zf in zfs:\r\n",
        "#   with ZipFile(zf, 'r') as z:\r\n",
        "#     z.extractall(\".//data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Levsk1ZeYwW"
      },
      "source": [
        "import gc\r\n",
        "import os\r\n",
        "import random\r\n",
        "import time\r\n",
        "import warnings\r\n",
        "warnings.simplefilter(\"ignore\")\r\n",
        "\r\n",
        "\r\n",
        "# from albumentations import *\r\n",
        "from albumentations.pytorch import ToTensor\r\n",
        "import cv2\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "# import segmentation_models_pytorch as smp\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "import tifffile as tiff\r\n",
        "import torch\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\r\n",
        "from torch.utils.data import DataLoader, Dataset, sampler, Subset\r\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD9Bx6BhhQ0W"
      },
      "source": [
        "DATA_PATH = \"./data/\"\r\n",
        "TRAIN_PATH = DATA_PATH + 'train/'\r\n",
        "MASKS_PATH = DATA_PATH + 'masks/'\r\n",
        "LABELS = DATA_PATH + 'train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUsch-mtiBLt"
      },
      "source": [
        "mean_v = [0.65459856,0.48386562,0.69428385]\r\n",
        "std = [0.15167958,0.23584107,0.13146145]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg5BMImui8Ck"
      },
      "source": [
        "from PIL import Image, ImageFile\r\n",
        "from tqdm import tqdm\r\n",
        "from collections import defaultdict\r\n",
        "from torchvision import transforms as T\r\n",
        "\r\n",
        "import albumentations as A\r\n",
        "\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO6QCGzTjEXi"
      },
      "source": [
        "def get_aug(p=1.0):\r\n",
        "    return A.Compose([\r\n",
        "        A.HorizontalFlip(),\r\n",
        "        A.VerticalFlip(),\r\n",
        "        A.RandomRotate90(),\r\n",
        "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.9, \r\n",
        "                         border_mode=cv2.BORDER_REFLECT),\r\n",
        "        A.OneOf([\r\n",
        "            A.OpticalDistortion(p=0.3),\r\n",
        "            A.GridDistortion(p=.1),\r\n",
        "            A.IAAPiecewiseAffine(p=0.3),\r\n",
        "        ], p=0.3),\r\n",
        "        A.OneOf([\r\n",
        "            A.HueSaturationValue(10,15,10),\r\n",
        "            A.CLAHE(clip_limit=2),\r\n",
        "            A.RandomBrightnessContrast(),            \r\n",
        "        ], p=0.3),\r\n",
        "    ], p=p)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class HuBMAPDataset(Dataset):\r\n",
        "    def __init__(self, image_ids, tfms = None):\r\n",
        "       \r\n",
        "        self.tfms = tfms\r\n",
        "        self.to_tensor = T.Compose([\r\n",
        "            T.ToTensor(),\r\n",
        "            T.Normalize(mean_v,\r\n",
        "                  std),\r\n",
        "        ])\r\n",
        "        \r\n",
        "        self.fnames = [fname for fname in os.listdir(TRAIN_PATH) if fname.split('_')[0] in image_ids]\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.fnames)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        fname = self.fnames[idx]\r\n",
        "        img_path = os.path.join(TRAIN_PATH,fname)\r\n",
        "        mask_path = os.path.join(MASKS_PATH,fname)\r\n",
        "        img = Image.open(img_path)\r\n",
        "        img = img.convert(\"RGB\")\r\n",
        "        img = np.array(img)\r\n",
        "        \r\n",
        "        mask = Image.open(mask_path)\r\n",
        "        mask = np.array(mask)\r\n",
        "        # convert to binary float matrix\r\n",
        "        mask = (mask >= 1).astype(\"float32\")\r\n",
        "        \r\n",
        "        if self.tfms:\r\n",
        "            augmented = self.tfms(image = img, mask = mask)\r\n",
        "            img = augmented[\"image\"]\r\n",
        "            mask = augmented[\"mask\"] \r\n",
        "        \r\n",
        "        # preprocess the image using provided\r\n",
        "        # preprocessing tensors. this is basically\r\n",
        "        # image normalization       \r\n",
        "#         img = (img / 255.0 - mean) / std\r\n",
        "            \r\n",
        "#         return {\r\n",
        "#                 \"image\": self.to_tensor(img),\r\n",
        "#                 \"mask\": T.ToTensor()(mask),\r\n",
        "#         }\r\n",
        "\r\n",
        "        return  self.to_tensor((img / 255.0).astype(\"float32\")), T.ToTensor()(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHlJyCxKjM_X"
      },
      "source": [
        "TRAINING_BATCH_SIZE = 32\r\n",
        "TEST_BATCH_SIZE = 32\r\n",
        "# number of epochs\r\n",
        "EPOCHS = 10\r\n",
        "DEVICE = \"cuda\"\r\n",
        "NUM_WORKERS = 0\r\n",
        "bs = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm5CDVBKjWGC"
      },
      "source": [
        "import torchvision\r\n",
        "def get_fcn_resnet50_model(pretrained = True):\r\n",
        "    model = torchvision.models.segmentation.fcn_resnet50(pretrained)\r\n",
        "    # preprocess_fn = smp.encoders.get_preprocessing_fn('resnet50', 'imagenet')\r\n",
        "    model.classifier[4] = nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\r\n",
        "    # model.aux_classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\r\n",
        "    model.to(DEVICE)\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IIZF42ExCXt"
      },
      "source": [
        "\"\"\"\r\n",
        "Lovasz-Softmax and Jaccard hinge loss in PyTorch\r\n",
        "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "from __future__ import print_function, division\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch.nn.functional as F\r\n",
        "import numpy as np\r\n",
        "try:\r\n",
        "    from itertools import  ifilterfalse\r\n",
        "except ImportError: # py3k\r\n",
        "    from itertools import  filterfalse\r\n",
        "\r\n",
        "\r\n",
        "def lovasz_grad(gt_sorted):\r\n",
        "    \"\"\"\r\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\r\n",
        "    See Alg. 1 in paper\r\n",
        "    \"\"\"\r\n",
        "    p = len(gt_sorted)\r\n",
        "    gts = gt_sorted.sum()\r\n",
        "    intersection = gts - gt_sorted.float().cumsum(0)\r\n",
        "    union = gts + (1 - gt_sorted).float().cumsum(0)\r\n",
        "    jaccard = 1. - intersection / union\r\n",
        "    if p > 1: # cover 1-pixel case\r\n",
        "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\r\n",
        "    return jaccard\r\n",
        "\r\n",
        "\r\n",
        "def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\r\n",
        "    \"\"\"\r\n",
        "    IoU for foreground class\r\n",
        "    binary: 1 foreground, 0 background\r\n",
        "    \"\"\"\r\n",
        "    if not per_image:\r\n",
        "        preds, labels = (preds,), (labels,)\r\n",
        "    ious = []\r\n",
        "    for pred, label in zip(preds, labels):\r\n",
        "        intersection = ((label == 1) & (pred == 1)).sum()\r\n",
        "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\r\n",
        "        if not union:\r\n",
        "            iou = EMPTY\r\n",
        "        else:\r\n",
        "            iou = float(intersection) / union\r\n",
        "        ious.append(iou)\r\n",
        "    iou = mean(ious)    # mean accross images if per_image\r\n",
        "    return 100 * iou\r\n",
        "\r\n",
        "\r\n",
        "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\r\n",
        "    \"\"\"\r\n",
        "    Array of IoU for each (non ignored) class\r\n",
        "    \"\"\"\r\n",
        "    if not per_image:\r\n",
        "        preds, labels = (preds,), (labels,)\r\n",
        "    ious = []\r\n",
        "    for pred, label in zip(preds, labels):\r\n",
        "        iou = []    \r\n",
        "        for i in range(C):\r\n",
        "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\r\n",
        "                intersection = ((label == i) & (pred == i)).sum()\r\n",
        "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\r\n",
        "                if not union:\r\n",
        "                    iou.append(EMPTY)\r\n",
        "                else:\r\n",
        "                    iou.append(float(intersection) / union)\r\n",
        "        ious.append(iou)\r\n",
        "    ious = map(mean, zip(*ious)) # mean accross images if per_image\r\n",
        "    return 100 * np.array(ious)\r\n",
        "\r\n",
        "\r\n",
        "# --------------------------- BINARY LOSSES ---------------------------\r\n",
        "\r\n",
        "\r\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\r\n",
        "    \"\"\"\r\n",
        "    Binary Lovasz hinge loss\r\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\r\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\r\n",
        "      per_image: compute the loss per image instead of per batch\r\n",
        "      ignore: void class id\r\n",
        "    \"\"\"\r\n",
        "    if per_image:\r\n",
        "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\r\n",
        "                          for log, lab in zip(logits, labels))\r\n",
        "    else:\r\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "def lovasz_hinge_flat(logits, labels):\r\n",
        "    \"\"\"\r\n",
        "    Binary Lovasz hinge loss\r\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\r\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\r\n",
        "      ignore: label to ignore\r\n",
        "    \"\"\"\r\n",
        "    if len(labels) == 0:\r\n",
        "        # only void pixels, the gradients should be 0\r\n",
        "        return logits.sum() * 0.\r\n",
        "    signs = 2. * labels.float() - 1.\r\n",
        "    errors = (1. - logits * Variable(signs))\r\n",
        "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\r\n",
        "    perm = perm.data\r\n",
        "    gt_sorted = labels[perm]\r\n",
        "    grad = lovasz_grad(gt_sorted)\r\n",
        "    #loss = torch.dot(F.relu(errors_sorted), Variable(grad))\r\n",
        "    loss = torch.dot(F.elu(errors_sorted)+1, Variable(grad))\r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\r\n",
        "    \"\"\"\r\n",
        "    Flattens predictions in the batch (binary case)\r\n",
        "    Remove labels equal to 'ignore'\r\n",
        "    \"\"\"\r\n",
        "    scores = scores.view(-1)\r\n",
        "    labels = labels.view(-1)\r\n",
        "    if ignore is None:\r\n",
        "        return scores, labels\r\n",
        "    valid = (labels != ignore)\r\n",
        "    vscores = scores[valid]\r\n",
        "    vlabels = labels[valid]\r\n",
        "    return vscores, vlabels\r\n",
        "\r\n",
        "\r\n",
        "class StableBCELoss(torch.nn.modules.Module):\r\n",
        "    def __init__(self):\r\n",
        "         super(StableBCELoss, self).__init__()\r\n",
        "    def forward(self, input, target):\r\n",
        "         neg_abs = - input.abs()\r\n",
        "         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\r\n",
        "         return loss.mean()\r\n",
        "\r\n",
        "\r\n",
        "def binary_xloss(logits, labels, ignore=None):\r\n",
        "    \"\"\"\r\n",
        "    Binary Cross entropy loss\r\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\r\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\r\n",
        "      ignore: void class id\r\n",
        "    \"\"\"\r\n",
        "    logits, labels = flatten_binary_scores(logits, labels, ignore)\r\n",
        "    loss = StableBCELoss()(logits, Variable(labels.float()))\r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "# --------------------------- MULTICLASS LOSSES ---------------------------\r\n",
        "\r\n",
        "\r\n",
        "def lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\r\n",
        "    \"\"\"\r\n",
        "    Multi-class Lovasz-Softmax loss\r\n",
        "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\r\n",
        "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\r\n",
        "      only_present: average only on classes present in ground truth\r\n",
        "      per_image: compute the loss per image instead of per batch\r\n",
        "      ignore: void class labels\r\n",
        "    \"\"\"\r\n",
        "    if per_image:\r\n",
        "        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), only_present=only_present)\r\n",
        "                          for prob, lab in zip(probas, labels))\r\n",
        "    else:\r\n",
        "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), only_present=only_present)\r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "def lovasz_softmax_flat(probas, labels, only_present=False):\r\n",
        "    \"\"\"\r\n",
        "    Multi-class Lovasz-Softmax loss\r\n",
        "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\r\n",
        "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\r\n",
        "      only_present: average only on classes present in ground truth\r\n",
        "    \"\"\"\r\n",
        "    C = probas.size(1)\r\n",
        "    losses = []\r\n",
        "    for c in range(C):\r\n",
        "        fg = (labels == c).float() # foreground for class c\r\n",
        "        if only_present and fg.sum() == 0:\r\n",
        "            continue\r\n",
        "        errors = (Variable(fg) - probas[:, c]).abs()\r\n",
        "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\r\n",
        "        perm = perm.data\r\n",
        "        fg_sorted = fg[perm]\r\n",
        "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\r\n",
        "    return mean(losses)\r\n",
        "\r\n",
        "\r\n",
        "def flatten_probas(probas, labels, ignore=None):\r\n",
        "    \"\"\"\r\n",
        "    Flattens predictions in the batch\r\n",
        "    \"\"\"\r\n",
        "    B, C, H, W = probas.size()\r\n",
        "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\r\n",
        "    labels = labels.view(-1)\r\n",
        "    if ignore is None:\r\n",
        "        return probas, labels\r\n",
        "    valid = (labels != ignore)\r\n",
        "    vprobas = probas[valid.nonzero().squeeze()]\r\n",
        "    vlabels = labels[valid]\r\n",
        "    return vprobas, vlabels\r\n",
        "\r\n",
        "def xloss(logits, labels, ignore=None):\r\n",
        "    \"\"\"\r\n",
        "    Cross entropy loss\r\n",
        "    \"\"\"\r\n",
        "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\r\n",
        "\r\n",
        "\r\n",
        "# --------------------------- HELPER FUNCTIONS ---------------------------\r\n",
        "\r\n",
        "def mean(l, ignore_nan=False, empty=0):\r\n",
        "    \"\"\"\r\n",
        "    nanmean compatible with generators.\r\n",
        "    \"\"\"\r\n",
        "    l = iter(l)\r\n",
        "    if ignore_nan:\r\n",
        "        l = ifilterfalse(np.isnan, l)\r\n",
        "    try:\r\n",
        "        n = 1\r\n",
        "        acc = next(l)\r\n",
        "    except StopIteration:\r\n",
        "        if empty == 'raise':\r\n",
        "            raise ValueError('Empty mean')\r\n",
        "        return empty\r\n",
        "    for n, v in enumerate(l, 2):\r\n",
        "        acc += v\r\n",
        "    if n == 1:\r\n",
        "        return acc\r\n",
        "    return acc / n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-oie3vQjZxN"
      },
      "source": [
        "model = get_fcn_resnet50_model(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ennlWChyjgKb"
      },
      "source": [
        "from fastai.vision.all import *\r\n",
        "# from lovasz import lovasz_hinge\r\n",
        "\r\n",
        "def symmetric_lovasz(outputs, targets):\r\n",
        "    outputs = outputs['out']\r\n",
        "    return 0.5*(lovasz_hinge(outputs, targets) + lovasz_hinge(-outputs, 1.0 - targets))\r\n",
        "\r\n",
        "class Dice_soft(Metric):\r\n",
        "    def __init__(self, axis=1): \r\n",
        "        self.axis = axis \r\n",
        "    def reset(self): self.inter,self.union = 0,0\r\n",
        "    def accumulate(self, learn):\r\n",
        "        pred,targ = flatten_check(torch.sigmoid(learn.pred['out']), learn.y)\r\n",
        "        self.inter += (pred*targ).float().sum().item()\r\n",
        "        self.union += (pred+targ).float().sum().item()\r\n",
        "    @property\r\n",
        "    def value(self): return 2.0 * self.inter/self.union if self.union > 0 else None\r\n",
        "    \r\n",
        "# dice with automatic threshold selection\r\n",
        "class Dice_th(Metric):\r\n",
        "    def __init__(self, ths=np.arange(0.1,0.9,0.05), axis=1): \r\n",
        "        self.axis = axis\r\n",
        "        self.ths = ths\r\n",
        "        \r\n",
        "    def reset(self): \r\n",
        "        self.inter = torch.zeros(len(self.ths))\r\n",
        "        self.union = torch.zeros(len(self.ths))\r\n",
        "        \r\n",
        "    def accumulate(self, learn):\r\n",
        "        pred,targ = flatten_check(torch.sigmoid(learn.pred['out']), learn.y)\r\n",
        "        for i,th in enumerate(self.ths):\r\n",
        "            p = (pred > th).float()\r\n",
        "            self.inter[i] += (p*targ).float().sum().item()\r\n",
        "            self.union[i] += (p+targ).float().sum().item()\r\n",
        "\r\n",
        "    @property\r\n",
        "    def value(self):\r\n",
        "        dices = torch.where(self.union > 0.0, \r\n",
        "                2.0*self.inter/self.union, torch.zeros_like(self.union))\r\n",
        "        return dices.max()\r\n",
        "    \r\n",
        "class Dice_th_pred(Metric):\r\n",
        "    def __init__(self, ths=np.arange(0.1,0.9,0.01), axis=1): \r\n",
        "        self.axis = axis\r\n",
        "        self.ths = ths\r\n",
        "        self.reset()\r\n",
        "        \r\n",
        "    def reset(self): \r\n",
        "        self.inter = torch.zeros(len(self.ths))\r\n",
        "        self.union = torch.zeros(len(self.ths))\r\n",
        "        \r\n",
        "    def accumulate(self,p,t):\r\n",
        "        pred,targ = flatten_check(p['out'], t)\r\n",
        "        for i,th in enumerate(self.ths):\r\n",
        "            p = (pred > th).float()\r\n",
        "            self.inter[i] += (p*targ).float().sum().item()\r\n",
        "            self.union[i] += (p+targ).float().sum().item()\r\n",
        "\r\n",
        "    @property\r\n",
        "    def value(self):\r\n",
        "        dices = torch.where(self.union > 0.0, 2.0*self.inter/self.union, \r\n",
        "                            torch.zeros_like(self.union))\r\n",
        "        return dices  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYs_tI5zjxAQ"
      },
      "source": [
        "class Model_pred:\r\n",
        "    def __init__(self, model, dl, tta:bool=True, half:bool=False):\r\n",
        "        self.model = model\r\n",
        "        self.dl = dl\r\n",
        "        self.tta = tta\r\n",
        "        self.half = half\r\n",
        "        \r\n",
        "    def __iter__(self):\r\n",
        "        self.model.eval()\r\n",
        "#         name_list = self.dl.dataset.fnames\r\n",
        "        count=0\r\n",
        "        with torch.no_grad():\r\n",
        "            for x,y in iter(self.dl):\r\n",
        "                x = x.cuda()\r\n",
        "                if self.half: x = x.half()\r\n",
        "                p = self.model(x)['out']\r\n",
        "                py = torch.sigmoid(p).detach()\r\n",
        "                if self.tta:\r\n",
        "                    #x,y,xy flips as TTA\r\n",
        "                    flips = [[-1],[-2],[-2,-1]]\r\n",
        "                    for f in flips:\r\n",
        "                        p = self.model(torch.flip(x,f))['out']\r\n",
        "                        p = torch.flip(p,f)\r\n",
        "                        py += torch.sigmoid(p).detach()\r\n",
        "                    py /= (1+len(flips))\r\n",
        "                if y is not None and len(y.shape)==4 and py.shape != y.shape:\r\n",
        "                    py = F.upsample(py, size=(y.shape[-2],y.shape[-1]), mode=\"bilinear\")\r\n",
        "                py = py.permute(0,2,3,1).float().cpu()\r\n",
        "                batch_size = len(py)\r\n",
        "                for i in range(batch_size):\r\n",
        "                    taget = y[i].detach().cpu() if y is not None else None\r\n",
        "#                     yield py[i],taget,name_list[count]\r\n",
        "                    yield py[i], taget\r\n",
        "                    count += 1\r\n",
        "                    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.dl.dataset)\r\n",
        "    \r\n",
        "class Dice_th_pred(Metric):\r\n",
        "    def __init__(self, ths=np.arange(0.1,0.9,0.01), axis=1): \r\n",
        "        self.axis = axis\r\n",
        "        self.ths = ths\r\n",
        "        self.reset()\r\n",
        "        \r\n",
        "    def reset(self): \r\n",
        "        self.inter = torch.zeros(len(self.ths))\r\n",
        "        self.union = torch.zeros(len(self.ths))\r\n",
        "        \r\n",
        "    def accumulate(self,p,t):\r\n",
        "        pred,targ = flatten_check(p, t)\r\n",
        "        for i,th in enumerate(self.ths):\r\n",
        "            p = (pred > th).float()\r\n",
        "            self.inter[i] += (p*targ).float().sum().item()\r\n",
        "            self.union[i] += (p+targ).float().sum().item()\r\n",
        "\r\n",
        "    @property\r\n",
        "    def value(self):\r\n",
        "        dices = torch.where(self.union > 0.0, 2.0*self.inter/self.union, \r\n",
        "                            torch.zeros_like(self.union))\r\n",
        "        return dices\r\n",
        "    \r\n",
        "def save_img(data,name,out):\r\n",
        "    data = data.float().cpu().numpy()\r\n",
        "    img = cv2.imencode('.png',(data*255).astype(np.uint8))[1]\r\n",
        "    out.writestr(name, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XNNCySwoHCk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHqwNNFAmzJT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k97TLbVRj4or"
      },
      "source": [
        "SEED = 42\r\n",
        "\r\n",
        "split_layers = lambda m: [\r\n",
        "                list(m.backbone.parameters()),\r\n",
        "                list(m.classifier.parameters())\r\n",
        "            ]\r\n",
        "\r\n",
        "def fastai_train(model):\r\n",
        "    dice = Dice_th_pred(np.arange(0.2,0.7,0.01))\r\n",
        "    df = pd.read_csv(LABELS)\r\n",
        "\r\n",
        "\r\n",
        "    nfolds = 4\r\n",
        "    kf = KFold(n_splits=nfolds,random_state=SEED,shuffle=True)\r\n",
        "\r\n",
        "    fold = 1\r\n",
        "    for tidx, vids in kf.split(df):\r\n",
        "      training_images = df.loc[tidx].id.values\r\n",
        "      validation_images = df.loc[vids].id.values\r\n",
        "      ds_t = HuBMAPDataset(\r\n",
        "          training_images,\r\n",
        "          get_aug(),\r\n",
        "      )\r\n",
        "      \r\n",
        "      # augmentations is disabled\r\n",
        "      ds_v = HuBMAPDataset(validation_images)\r\n",
        "\r\n",
        "      data = ImageDataLoaders.from_dsets(ds_t,ds_v,bs=bs,\r\n",
        "                  num_workers=NUM_WORKERS,pin_memory=True).cuda()\r\n",
        "  #     model = UneXt50().cuda()\r\n",
        "      learn = Learner(data, model, loss_func=symmetric_lovasz,\r\n",
        "                  metrics=[Dice_soft(),Dice_th()], \r\n",
        "                  splitter=split_layers).to_fp16(clip=0.5)\r\n",
        "      \r\n",
        "      #start with training the head\r\n",
        "      learn.freeze_to(-1) #doesn't work\r\n",
        "      for param in learn.opt.param_groups[0]['params']:\r\n",
        "          param.requires_grad = False\r\n",
        "      learn.fit_one_cycle(4, lr_max=0.5e-2)\r\n",
        "\r\n",
        "      #continue training full model\r\n",
        "      learn.unfreeze()\r\n",
        "      learn.fit_one_cycle(16, lr_max=slice(2e-4,2e-3),\r\n",
        "          cbs=SaveModelCallback(monitor='dice_th',comp=np.greater))\r\n",
        "      torch.save(learn.model.state_dict(),f'/content/drive/MyDrive/model_{fold}.pth')\r\n",
        "      fold += 1\r\n",
        "    \r\n",
        "      #model evaluation on val and saving the masks\r\n",
        "      mp = Model_pred(learn.model,learn.dls.loaders[1])\r\n",
        "  #     with zipfile.ZipFile('val_masks_tta.zip', 'a') as out:\r\n",
        "      for p in progress_bar(mp):\r\n",
        "        dice.accumulate(p[0],p[1])\r\n",
        "#             save_img(p[0],p[2],out)\r\n",
        "      gc.collect()\r\n",
        "    return dice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tLo66LdLvGYL",
        "outputId": "df42f277-f6b2-4bcf-d81b-b6d44910beeb"
      },
      "source": [
        "dice = fastai_train(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>dice_soft</th>\n",
              "      <th>dice_th</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.292718</td>\n",
              "      <td>0.602780</td>\n",
              "      <td>0.825245</td>\n",
              "      <td>0.864945</td>\n",
              "      <td>01:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.290839</td>\n",
              "      <td>0.630521</td>\n",
              "      <td>0.819901</td>\n",
              "      <td>0.860032</td>\n",
              "      <td>02:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.301113</td>\n",
              "      <td>0.610761</td>\n",
              "      <td>0.809472</td>\n",
              "      <td>0.862700</td>\n",
              "      <td>01:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.289200</td>\n",
              "      <td>0.606217</td>\n",
              "      <td>0.819541</td>\n",
              "      <td>0.863548</td>\n",
              "      <td>02:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>dice_soft</th>\n",
              "      <th>dice_th</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.288602</td>\n",
              "      <td>0.608426</td>\n",
              "      <td>0.820221</td>\n",
              "      <td>0.862990</td>\n",
              "      <td>02:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.306600</td>\n",
              "      <td>0.618582</td>\n",
              "      <td>0.819936</td>\n",
              "      <td>0.860258</td>\n",
              "      <td>02:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.335368</td>\n",
              "      <td>0.631761</td>\n",
              "      <td>0.780403</td>\n",
              "      <td>0.856468</td>\n",
              "      <td>02:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.333284</td>\n",
              "      <td>0.616799</td>\n",
              "      <td>0.801591</td>\n",
              "      <td>0.859965</td>\n",
              "      <td>03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.333940</td>\n",
              "      <td>0.664127</td>\n",
              "      <td>0.802355</td>\n",
              "      <td>0.854537</td>\n",
              "      <td>02:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.341917</td>\n",
              "      <td>0.700413</td>\n",
              "      <td>0.789315</td>\n",
              "      <td>0.837989</td>\n",
              "      <td>02:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.337328</td>\n",
              "      <td>0.650184</td>\n",
              "      <td>0.760440</td>\n",
              "      <td>0.843190</td>\n",
              "      <td>02:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.331236</td>\n",
              "      <td>0.648349</td>\n",
              "      <td>0.782961</td>\n",
              "      <td>0.855500</td>\n",
              "      <td>02:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.318455</td>\n",
              "      <td>0.633318</td>\n",
              "      <td>0.810512</td>\n",
              "      <td>0.858031</td>\n",
              "      <td>02:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.304656</td>\n",
              "      <td>0.665895</td>\n",
              "      <td>0.796016</td>\n",
              "      <td>0.851578</td>\n",
              "      <td>02:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.290154</td>\n",
              "      <td>0.615983</td>\n",
              "      <td>0.823052</td>\n",
              "      <td>0.868135</td>\n",
              "      <td>02:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.305387</td>\n",
              "      <td>0.595111</td>\n",
              "      <td>0.805635</td>\n",
              "      <td>0.865042</td>\n",
              "      <td>02:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.290527</td>\n",
              "      <td>0.614626</td>\n",
              "      <td>0.820384</td>\n",
              "      <td>0.866242</td>\n",
              "      <td>02:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.287021</td>\n",
              "      <td>0.617559</td>\n",
              "      <td>0.824079</td>\n",
              "      <td>0.865863</td>\n",
              "      <td>02:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.257899</td>\n",
              "      <td>0.598407</td>\n",
              "      <td>0.820864</td>\n",
              "      <td>0.867732</td>\n",
              "      <td>02:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.268378</td>\n",
              "      <td>0.595107</td>\n",
              "      <td>0.825764</td>\n",
              "      <td>0.868882</td>\n",
              "      <td>02:51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with dice_th value: 0.8629904389381409.\n",
            "Better model found at epoch 10 with dice_th value: 0.8681349754333496.\n",
            "Better model found at epoch 15 with dice_th value: 0.8688820004463196.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/833 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-0269ee1e1a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfastai_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-aa4c3e34cb12>\u001b[0m in \u001b[0;36mfastai_train\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;31m#     with zipfile.ZipFile('val_masks_tta.zip', 'a') as out:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;31m#             save_img(p[0],p[2],out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-af0fa6456482>\u001b[0m in \u001b[0;36maccumulate\u001b[0;34m(self, p, t)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH1-_K_dyzXW"
      },
      "source": [
        "# %debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKUZ5cjezAMc",
        "outputId": "20d21d1f-5aaa-47cd-b432-6bb3d9ad8393"
      },
      "source": [
        "# training_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 4, 5, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "wP9BMd5stwH1",
        "outputId": "4848da93-71fb-4564-df37-7644fb963e57"
      },
      "source": [
        "dices = dice.value\r\n",
        "noise_ths = dice.ths\r\n",
        "best_dice = dices.max()\r\n",
        "best_thr = noise_ths[dices.argmax()]\r\n",
        "plt.figure(figsize=(8,4))\r\n",
        "plt.plot(noise_ths, dices, color='blue')\r\n",
        "plt.vlines(x=best_thr, ymin=dices.min(), ymax=dices.max(), colors='black')\r\n",
        "d = dices.max() - dices.min()\r\n",
        "plt.text(noise_ths[-1]-0.1, best_dice-0.1*d, f'DICE = {best_dice:.3f}', fontsize=12);\r\n",
        "plt.text(noise_ths[-1]-0.1, best_dice-0.2*d, f'TH = {best_thr:.3f}', fontsize=12);\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN8Zs7AcRIfB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}